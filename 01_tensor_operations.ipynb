{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "01-tensor-operations.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aayrm5/Zero_to_GANS/blob/main/01_tensor_operations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-j_XeDHse0Ty",
        "outputId": "5f8feccb-5cbd-4b86-cd2e-5c916979641b"
      },
      "source": [
        "# Jovian Commit Essentials\n",
        "# Please retain and execute this cell without modifying the contents for `jovian.commit` to work\n",
        "!pip install jovian --upgrade -q\n",
        "import jovian\n",
        "jovian.utils.colab.set_colab_file_id('1wAIsWYLVLy18ZSXGjaA7ZakRqJmTvUA8')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█████                           | 10kB 20.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 20kB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 30kB 11.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 40kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 61kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.2MB/s \n",
            "\u001b[?25h  Building wheel for uuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn3WKmWMe0T0"
      },
      "source": [
        "# PyTorch functions for operations on tensors\n",
        "\n",
        "An short introduction about PyTorch and about the chosen functions. \n",
        "\n",
        "- torch.from_numpy\n",
        "- torch.complex\n",
        "- torch.hstack\n",
        "- tensor.narrow\n",
        "- torch.transpose\n",
        "\n",
        "Before we begin, let's install and import PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBso8JB7e0T0"
      },
      "source": [
        "# Uncomment and run the appropriate command for your operating system, if required\n",
        "\n",
        "# Linux / Binder\n",
        "# !pip install numpy torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# Windows\n",
        "# !pip install numpy torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# MacOS\n",
        "# !pip install numpy torch torchvision torchaudio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifWJ6Fhue0T0"
      },
      "source": [
        "# Import torch and other required modules\n",
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCdQ7bwigNzw"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRGJYHzxe0T1"
      },
      "source": [
        "\n",
        "\n",
        "# This is formatted as code\n",
        "\n",
        "## Function 1 - torch.from_numpy\n",
        "\n",
        "Creates a Tensor from a numpy.ndarray. The returned tensor and ndarray share the same memory. Modifications to the tensor will be reflected in the ndarray and vice versa. The returned tensor is not resizable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dl8j0Az9e0T1",
        "outputId": "aefb96eb-0c19-4106-a832-7e2dbe8da895"
      },
      "source": [
        "# Example 1 - working \n",
        "arr = np.array([[1,2,3],[5,6,7]])\n",
        "\n",
        "ten = torch.from_numpy(arr)\n",
        "print(ten)\n",
        "print(ten.dtype)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [5, 6, 7]])\n",
            "torch.int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A4gxUC2e0T4"
      },
      "source": [
        "The above example shows how a 2D numpy array has been converted to tensor of int64."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdFEN8NDe0T4",
        "outputId": "b459be66-b6c8-42ae-e7ea-7f8327a6b11a"
      },
      "source": [
        "# Example 2 - working\n",
        "arr1 = np.random.randn(5,5)\n",
        "print(arr1)\n",
        "print(arr1.dtype)\n",
        "\n",
        "t1 = torch.from_numpy(arr1)\n",
        "print(t1)\n",
        "print(t1.dtype)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.47933258 -0.93466813 -0.88072474  0.29290626 -0.98801339]\n",
            " [ 0.06330733  0.51426056  0.9141022   0.39718783 -1.62442852]\n",
            " [-0.7000188  -0.94014641  0.04239408  0.48902126 -0.35258211]\n",
            " [-1.22310722  0.93022085  1.59484913  0.64926354  0.01355259]\n",
            " [-0.14499633 -0.25924037 -0.05237166 -1.46272417 -0.47922014]]\n",
            "float64\n",
            "tensor([[-0.4793, -0.9347, -0.8807,  0.2929, -0.9880],\n",
            "        [ 0.0633,  0.5143,  0.9141,  0.3972, -1.6244],\n",
            "        [-0.7000, -0.9401,  0.0424,  0.4890, -0.3526],\n",
            "        [-1.2231,  0.9302,  1.5948,  0.6493,  0.0136],\n",
            "        [-0.1450, -0.2592, -0.0524, -1.4627, -0.4792]], dtype=torch.float64)\n",
            "torch.float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiOlr-mBe0T4"
      },
      "source": [
        "Example 2 shows how numpy array of shape 5x5 is transformed into tensor of same float64 data type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "MQ_KCbMce0T4",
        "outputId": "066d4255-249d-4171-f7ca-a288ab79c738"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "arr2 = np.array([[1,2,3],['a','b','c']])\n",
        "print(arr2.dtype)\n",
        "\n",
        "t3 = torch.from_numpy(arr2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<U21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-f41523f83c7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mt3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.str_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjQEfXjHe0T5"
      },
      "source": [
        "The array, arr2 has datatypes strings in one of the sub arrays. This is not supported by the tensors. As mentioned in the error, the only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls7XnhXoe0T5"
      },
      "source": [
        "Closing comments about when to use this function:\n",
        "\n",
        "You could use the from_numpy function when you want to convert an numpy array into a tensor, given you respect the tensor restrictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcRCjTR9e0T5"
      },
      "source": [
        "Let's save our work using Jovian before continuing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7drLiipe0T5"
      },
      "source": [
        "!pip install jovian --upgrade --quiet"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPThyeK7e0T5"
      },
      "source": [
        "import jovian"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "ogm0QYvfe0T5",
        "outputId": "d223da67-935e-4c2e-e70b-cfbe80b81281"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Please enter your API key ( from https://jovian.ai/ ):\u001b[0m\n",
            "API KEY: ··········\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/aayrm5/01-tensor-operations\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/aayrm5/01-tensor-operations'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7K4PhZrue0T5"
      },
      "source": [
        "## Function 2 - torch.complex\n",
        "\n",
        "Constructs a complex tensor with its real part equal to real and it's imaginary part equal to imag. Takes two tensors as input and outs one complex tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27OTito7e0T6",
        "outputId": "74ec1b6d-c720-461f-9740-9bf906e6aaef"
      },
      "source": [
        "# Example 1 - working\n",
        "real = torch.tensor([1,2], dtype = torch.float32)\n",
        "imag = torch.tensor([3,4], dtype=torch.float32)\n",
        "\n",
        "z = torch.complex(real,imag)\n",
        "print(z.dtype)\n",
        "print(z)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.complex64\n",
            "tensor([1.+3.j, 2.+4.j])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3czKoaVe0T6"
      },
      "source": [
        "The above example shows how to contruct a complex tensor by joining a real and imaginaroy part of tensors.\n",
        "Note that, when real and imag are of data type float32 the output has a complex of datatype complex64."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omN7jvIRe0T6",
        "outputId": "bb76f349-38b5-400b-d052-582ad720c37f"
      },
      "source": [
        "# Example 2 - working\n",
        "real = torch.tensor([[1,2,3],[7,8,9]], dtype = torch.float64)\n",
        "imag = torch.tensor([[11,12,13],[87,89,7878]], dtype = torch.float64)\n",
        "\n",
        "z = torch.complex(real, imag)\n",
        "print(z)\n",
        "print(z.dtype)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.+11.j, 2.+12.j, 3.+13.j],\n",
            "        [7.+87.j, 8.+89.j, 9.+7878.j]], dtype=torch.complex128)\n",
            "torch.complex128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT_LR7Cme0T6"
      },
      "source": [
        "The above example shows that complex accepts real and imag with same dtype. Also now that the dtype are of float64, the output complex has a datatype of complex128.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "3FzMS0Rie0T6",
        "outputId": "3c89b43b-79ad-4457-d672-d5e37da4f2c4"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "real = torch.tensor([[1,2,3],[7,8,9]], dtype = torch.int64)\n",
        "imag = torch.tensor([[11,12,13],[87,89,7878]], dtype = torch.int64)\n",
        "\n",
        "z = torch.complex(real, imag)\n",
        "print(z)\n",
        "print(z.dtype)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-b8c473458b74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m87\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m89\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7878\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected both inputs to be Float or Double tensors but got Long and Long"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMzhZNdme0T6"
      },
      "source": [
        "The torch.complex function only accepts real and imag tensors with datatypes of float or double and both of them should have similar datatypes for it to function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSgh056oe0T6"
      },
      "source": [
        "Closing comments about when to use this function:\n",
        "\n",
        "torch.complex function is really useful in building complex equation real quick. Just keep in mind the limitations of this function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "sYmJJzpPe0T6",
        "outputId": "6b7ac189-95cc-4d8b-e704-6dc73e5e3afa"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/aayrm5/01-tensor-operations\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/aayrm5/01-tensor-operations'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abeXUux5e0T6"
      },
      "source": [
        "## Function 3 - torch.hstack\n",
        "\n",
        "The above function helps stack tensors in sequence horizontally (column wise). Takes multiple tensors as input and returns one concatanated tensor as output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njTYQccpe0T6",
        "outputId": "e55aa686-034a-4c46-852e-31a07dca85bc"
      },
      "source": [
        "# Example 1 - working\n",
        "t1 = torch.tensor([1, 2, 3, 5, 6])\n",
        "print(t1.dtype, end='\\n\\n')\n",
        "t2 = torch.tensor([4, 5, 6, 7, 8])\n",
        "print(t2.dtype, end='\\n\\n')\n",
        "\n",
        "t3 = torch.hstack((t1,t2))\n",
        "print(t3)\n",
        "print(t3.dtype)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.int64\n",
            "\n",
            "torch.int64\n",
            "\n",
            "tensor([1, 2, 3, 5, 6, 4, 5, 6, 7, 8])\n",
            "torch.int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFXQn_FQe0T7"
      },
      "source": [
        "Explanation about example1:\n",
        "- t3 is a result of horizontal contactination of two tensors t1 & t2. The datatype remained same as t1 & t2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RohfZuv7e0T7",
        "outputId": "2800a23c-6085-4606-f2e1-0d20199c519e"
      },
      "source": [
        "# Example 2 - working\n",
        "t1 = torch.tensor([[1.5],[2.5],[3.5]])\n",
        "print(t1.dtype, t1.shape, end='\\n\\n')\n",
        "t2 = torch.tensor([[4],[5],[6]])\n",
        "print(t2.dtype, t2.shape, end='\\n\\n')\n",
        "t3 = torch.hstack((t1,t2))\n",
        "print(t3)\n",
        "print(t3.dtype, t3.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.float32 torch.Size([3, 1])\n",
            "\n",
            "torch.int64 torch.Size([3, 1])\n",
            "\n",
            "tensor([[1.5000, 4.0000],\n",
            "        [2.5000, 5.0000],\n",
            "        [3.5000, 6.0000]])\n",
            "torch.float32 torch.Size([3, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sb2NwSqGe0T7"
      },
      "source": [
        "Explanation about example:\n",
        "- This example has two tensors with same size of [3,1] but with different datatypes of float32 and int64, the resultant tensor has a datatype of float32 as the entire tensor has been converted into suitable, one datatype."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "X0XqDfzXe0T7",
        "outputId": "af57ef8f-6c8c-485c-dddb-fc8bfaf33dc1"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "\n",
        "t1 = torch.tensor([[1.5],[2.5],[3.5]])\n",
        "print(t1.dtype, t1.shape, end='\\n\\n')\n",
        "t2 = torch.tensor([[4],[5]])\n",
        "print(t2.dtype, t2.shape, end='\\n\\n')\n",
        "t3 = torch.hstack((t1,t2))\n",
        "print(t3)\n",
        "print(t3.dtype, t3.shape)\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.float32 torch.Size([3, 1])\n",
            "\n",
            "torch.int64 torch.Size([2, 1])\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-3a9f5f072f34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mt3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Got 3 and 2 in dimension 0 (The offending index is 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fij6IZ_Qe0T7"
      },
      "source": [
        "Explanation about example:\n",
        "- passing tensors with different dimensions to the hstack function breaks it.\n",
        "- As the error suggests, sizes of tensors must match for it to work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJu0CnNke0T7"
      },
      "source": [
        "Closing comments about when to use this function:\n",
        "- tensor.hstack function comes in handy when you want to join multiple tensors, just be cautious about their datatypes and shape. Remember to pass in tensors of same dtype as arguements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7vC4k7ke0T7",
        "outputId": "e0d06c0f-cafd-451a-ce78-c7231bef4ea5"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[jovian] Attempting to save notebook..\u001b[0m\n",
            "[jovian] Updating notebook \"aakashns/01-tensor-operations\" on https://jovian.ai/\u001b[0m\n",
            "[jovian] Uploading notebook..\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/aakashns/01-tensor-operations\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://jovian.ai/aakashns/01-tensor-operations'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj_zubmle0T8"
      },
      "source": [
        "## Function 4 - tensor.narrow\n",
        "\n",
        "This function returns a new tensor that is a narrowed version of input tensor. Takes multiple arguments such as input, dim, start, length. The returned tensor and the input tensor share the same memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBRUUsTqe0T8",
        "outputId": "80f51658-b23c-464d-bc47-887f18bb77db"
      },
      "source": [
        "# Example 1 - working\n",
        "t4 = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "print(t4)\n",
        "\n",
        "nar_0 = torch.narrow(t4, 0, 1, 2)\n",
        "print(nar_0)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "tensor([[4, 5, 6],\n",
            "        [7, 8, 9]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHeBAeC_e0T8"
      },
      "source": [
        "Explanation about example:\n",
        "- The above function extracts a subset of the tensor t4 by starting at index 1, dimention 0 (specifies rows) and the length of 2 which grabs 2 rows out of 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6HwWoLbe0T8",
        "outputId": "6c32521e-d164-4ce1-a0e4-90712f237d35"
      },
      "source": [
        "# Example 2 - working\n",
        "print(t4)\n",
        "\n",
        "nar_1 = torch.narrow(t4, 1, 0, 2)\n",
        "print(nar_1)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "tensor([[1, 2],\n",
            "        [4, 5],\n",
            "        [7, 8]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG7k9YHSe0T8"
      },
      "source": [
        "Explanation about example:\n",
        "- The above function has been sliced vertically when you pass a dimention 1, it is starting at 0 index for columns and grabs 2 of them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "6bhKzjXae0T8",
        "outputId": "0e1b3413-249c-4fcd-a575-f40b4a8103e3"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "print(t4)\n",
        "\n",
        "nar_1 = torch.narrow(t4, 1, 0, 4)\n",
        "print(nar_1)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-c770c218a869>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnar_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnar_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: start (0) + length (4) exceeds dimension size (3)."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrSvKGqbe0T8"
      },
      "source": [
        "Explanation about example:\n",
        " - touch.narrow function breaks when you pass the dimension greater than the dimension of the input tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXdNN9nYe0T8"
      },
      "source": [
        "Closing comments about when to use this function:\n",
        "- touch.narrow function is helpful in subsetting tensors and having multiple inputs makes it easier to mention the shape and size of the subset tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "MZI_s9QXe0T8",
        "outputId": "ecd03952-cabd-425b-9a2f-779d327a2fcb"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/aayrm5/01-tensor-operations\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/aayrm5/01-tensor-operations'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeZ1PHTve0T9"
      },
      "source": [
        "## Function 5 - torch.transpose\n",
        "\n",
        "The above function returns a tensor that is a transposed version of input. This function accpets parameters as input, dim0, and dim1. The given dimensions dim0 & dim1 are swapped."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wr-ZSCRae0T9",
        "outputId": "804ea63e-035a-4e7d-cbf8-b14707c24e01"
      },
      "source": [
        "# Example 1 - working\n",
        "tt1 = torch.randn(5,3)\n",
        "print(tt1)\n",
        "\n",
        "tran1 = torch.transpose(tt1, 0, 1)\n",
        "print(tran1)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.3004,  0.1901,  2.3058],\n",
            "        [ 1.0754, -0.4700, -0.8900],\n",
            "        [ 0.1029,  0.1087,  0.3508],\n",
            "        [ 0.1336,  2.5423,  1.5134],\n",
            "        [ 1.2471, -0.0053, -0.3461]])\n",
            "tensor([[-0.3004,  1.0754,  0.1029,  0.1336,  1.2471],\n",
            "        [ 0.1901, -0.4700,  0.1087,  2.5423, -0.0053],\n",
            "        [ 2.3058, -0.8900,  0.3508,  1.5134, -0.3461]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4ceUGLPe0T9"
      },
      "source": [
        "Explanation about example:\n",
        "- The above function transposed the tensor of size [5,3] to a tensor of size [3,5]. 0, 1 in the above example denotes that they'd be transposed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPir6Vx1e0T9",
        "outputId": "05340cef-362f-4362-969c-b559a00c1395"
      },
      "source": [
        "# Example 2 - working\n",
        "print(tt1)\n",
        "\n",
        "tran2 = torch.transpose(tt1, 1, 0)\n",
        "print(tran2)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.3004,  0.1901,  2.3058],\n",
            "        [ 1.0754, -0.4700, -0.8900],\n",
            "        [ 0.1029,  0.1087,  0.3508],\n",
            "        [ 0.1336,  2.5423,  1.5134],\n",
            "        [ 1.2471, -0.0053, -0.3461]])\n",
            "tensor([[-0.3004,  1.0754,  0.1029,  0.1336,  1.2471],\n",
            "        [ 0.1901, -0.4700,  0.1087,  2.5423, -0.0053],\n",
            "        [ 2.3058, -0.8900,  0.3508,  1.5134, -0.3461]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrlWtRG-e0T9"
      },
      "source": [
        "Explanation about example:\n",
        "- The above function transposed the tensor of size [5,3] to a tensor of size [3,5]. 1,0  in the above example denotes that they'd be transposed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "-zPJ4fnJe0T9",
        "outputId": "2dfa3da3-bbc2-48a1-d71f-3f9b98658c81"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "tran2 = torch.transpose(tt1,1, 2)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-dd450531e105>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtran2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtt1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu4WTEG3e0T9"
      },
      "source": [
        "Explanation about example:\n",
        " - Dimensions for the transpose were out of range. Expecting to get the 0,1 or 1,2 but got different numbers which were out of range."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiiBFA0Ze0T9"
      },
      "source": [
        "Closing comments about when to use this function:\n",
        " - transpose function is very helpful when you want to do matrix multiplication of tensors with same shape( matrix multiplication is not possible on matrices with same shape), hence the transpose of them is required."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "95IXlEBpe0T9",
        "outputId": "dbb4c85b-c65f-4a25-b400-ee50489e3d21"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/aayrm5/01-tensor-operations\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/aayrm5/01-tensor-operations'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDEZtQLfe0T-"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "The functions discussed are one of the important ones while doing tensor operations. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tiu7Mzf5e0T-"
      },
      "source": [
        "## Reference Links\n",
        "Provide links to your references and other interesting articles about tensors\n",
        "* Official documentation for tensor operations: https://pytorch.org/docs/stable/torch.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "vomGFlM6e0T-",
        "outputId": "3dabd404-2068-4247-a7b0-7574b5b57e31"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/aayrm5/01-tensor-operations\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/aayrm5/01-tensor-operations'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "440forgCe0T-",
        "outputId": "1f36d646-ef8b-4547-80ea-0d36a0d5e5fc"
      },
      "source": [
        "jovian.submit(project='01-tensor-operations',assignment=\"zerotogans-a1\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/aayrm5/01-tensor-operations\u001b[0m\n",
            "[jovian] Submitting assignment..\u001b[0m\n",
            "[jovian] Verify your submission at https://jovian.ai/learn/deep-learning-with-pytorch-zero-to-gans/assignment/assignment-1-all-about-torch-tensor\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SeQB0S9Huth"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}